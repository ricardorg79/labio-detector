package main

import (
	"fmt"
	"image"
	"image/color"
	"io/ioutil"
	"math/rand"
	"os"
	"os/exec"
	"path"
	"strings"
	"time"

	tg "github.com/galeone/tfgo"
	tf "github.com/tensorflow/tensorflow/tensorflow/go"
	"github.com/tensorflow/tensorflow/tensorflow/go/op"
	"gocv.io/x/gocv"

	"archive/zip"
	"bufio"
	"io"
	"log"
	"net/http"
	//"os"
	"path/filepath"
	//tf "github.com/tensorflow/tensorflow/tensorflow/go"
	//"github.com/tensorflow/tensorflow/tensorflow/go/op"
)

var (
	id       = 1
	pre      = rand.New(rand.NewSource(time.Now().UnixNano())).Int()
	deviceID = 0
	xmlFile  = "/usr/local/share/OpenCV/haarcascades/haarcascade_frontalface_alt2.xml"
)

func main() {
	//tgRecognizer()
	//os.Exit(0)

	// open webcam
	webcam, err := gocv.VideoCaptureDevice(int(deviceID))
	if err != nil {
		fmt.Println(err)
		return
	}
	defer func() { _ = webcam.Close() }()

	detector := newFaceDetector(xmlFile)
	defer detector.close()

	showCamera(webcam, detector)

	select {}
}

func showCamera(webcam *gocv.VideoCapture, detector *faceDetector) {
	// open display window
	window := gocv.NewWindow("Face Detect")
	window.ResizeWindow(512, 512)
	defer func() { _ = window.Close() }()

	// prepare image matrix
	img := gocv.NewMat()
	defer func() { _ = img.Close() }()

	// color for the rect when faces detected
	blue := color.RGBA{0, 0, 255, 0}

	imgChan := make(chan string, 100)
	scoreChan := make(chan map[string]float32, 100)
	go func() {
		for scoreMap := range scoreChan {
			fmt.Println("=============================")
			for k, v := range scoreMap {
				fmt.Printf("%s->%2.4f\n", k, v)
			}
		}
	}()
	rnd := rand.New(rand.NewSource(time.Now().UnixNano()))
	go startImageLabeler(imgChan, scoreChan)

	//
	for {
		if ok := webcam.Read(&img); !ok {
			panic("cannot read device\n")
		}
		if img.Empty() {
			continue
		}

		//
		//img2 := gocv.NewMat()
		//defer func() { _ = img2.Close() }()
		//gocv.Flip(img, img2, -1)

		/*
			mini := gocv.NewMat()
			defer func() { _ = mini.Close() }()
			x := img.Size()[0]
			y := img.Size()[1]
			mini := gocv.Resize(img, &mini, mini.Size(), x/4.0, y/4.0, gocv.InterpolationDefault)
		*/

		// detect faces
		detector.detect(img, func(rects []image.Rectangle) {
			fmt.Printf("found %d faces\n", len(rects))

			// draw a rectangle around each face on the original image,
			// along with text identifying as "Human"
			for _, r := range rects {

				//
				//
				faceImage := img.Region(r)
				defer func() { _ = faceImage.Close() }()
				faceImageName := path.Join(
					"./images",
					fmt.Sprintf("test-%d.jpg", rnd.Int()),
				)
				gocv.IMWrite(faceImageName, faceImage)
				imgChan <- faceImageName
				//

				/*
					scores := scoreImage(faceImageName)
					txt := scoreToLabels(scores)
				*/
				txt := "Human"

				gocv.Rectangle(&img, r, blue, 3)
				size := gocv.GetTextSize(txt, gocv.FontHersheyPlain, 1.2, 2)
				pt := image.Pt(r.Min.X+(r.Min.X/2)-(size.X/2), r.Min.Y-2)
				gocv.PutText(&img, txt, pt, gocv.FontHersheyPlain, 1.2, blue, 2)
			}

			// show the image in the window, and wait 1 millisecond
			window.IMShow(img)

		})
		if window.WaitKey(1) >= 0 {
			break
		}
		//time.Sleep(time.Millisecond * 2000) // sleep 1 second
	}
}

type faceDetector struct {
	inFlight   bool
	closed     bool
	classifier gocv.CascadeClassifier
}

func newFaceDetector(xmlFile string) *faceDetector {
	// load classifier to recognize faces
	classifier := gocv.NewCascadeClassifier()

	if !classifier.Load(xmlFile) {
		fmt.Printf("Error reading cascade file: %v\n", xmlFile)
		panic("error")
	}
	return &faceDetector{classifier: classifier, inFlight: false}
}

func (fd *faceDetector) detect(img gocv.Mat, f func([]image.Rectangle)) {
	if fd.inFlight || fd.closed {
		return
	}

	fd.inFlight = true
	go func() {
		imgCopy := gocv.NewMat()
		defer func() { _ = imgCopy.Close() }()
		img.CopyTo(&imgCopy)
		rects := fd.classifier.DetectMultiScale(imgCopy)
		fmt.Printf("Dtected %d faces", len(rects))
		if !fd.closed {
			f(rects)
		}
		fd.inFlight = false
	}()

}

func (fd *faceDetector) close() {
	defer func() { _ = fd.classifier.Close() }()
}

func playSiren() {
	var playCmd string
	var err error
	playCmd, err = exec.LookPath("play")
	if err != nil {
		panic(err)
	}
	cmd := exec.Command(playCmd, "siren.wav")
	err = cmd.Run()
	if err != nil {
		panic(err)
	}
}

func scoreImage(fileName string) []float32 {
	modelFile := "retrained_graph.pb"
	var inputHeight int32 = 224
	var inputWidth int32 = 224
	var inputMean float32 = 128
	var inputStd float32 = 128

	graph := loadGraph(modelFile)
	tensor := readTensorFromImageFile(
		fileName,
		inputHeight,
		inputWidth,
		inputMean,
		inputStd,
	)

	//
	sess, err := tf.NewSession(graph, nil)
	if err != nil {
		panic(err)
	}
	defer sess.Close()

	// accepts batches of image data as input.
	output, err := sess.Run(
		map[tf.Output]*tf.Tensor{
			graph.Operation("input").Output(0): tensor,
		},
		[]tf.Output{
			graph.Operation("output").Output(0),
		},
		nil)
	if err != nil {
		panic(err)
	}
	// output[0].Value() is a vector containing probabilities of
	// labels for each image in the "batch". The batch size was 1.
	// Find the most probably label index.
	probabilities := output[0].Value().([][]float32)[0]
	return probabilities
}

func loadGraph(modelFile string) *tf.Graph {
	graph := tf.NewGraph()
	file, err := os.Open(modelFile)
	if err != nil {
		panic(err)
	}
	b, err := ioutil.ReadAll(file)
	if err != nil {
		panic(err)
	}
	graph.Import(b, "imported")
	return graph
}

func readTensorFromImageFile(fileName string, inputHeight, inputWidth int32, inputMean float32, inputStd float32) *tf.Tensor {
	//outputName := "normalized"
	scope := op.NewScope()

	fileReader := op.Placeholder(scope, tf.String)
	var imageReader tf.Output

	if strings.HasSuffix(fileName, ".png") {
		imageReader = op.DecodePng(scope, fileReader, op.DecodePngChannels(3)) //, name='png_reader')
	} else if strings.HasSuffix(fileName, ".gif") {
		imageReader = op.DecodeGif(scope, fileReader) //, name='gif_reader'))
	} else if strings.HasSuffix(fileName, ".bmp") {
		imageReader = op.DecodeBmp(scope, fileReader) //, name='bmp_reader')
	} else {
		imageReader = op.DecodeJpeg(scope, fileReader, op.DecodeJpegChannels(3)) //, name='jpeg_reader')
	}

	//
	floatCaster := op.Cast(scope, imageReader, tf.Float)
	dimsExpander := op.ExpandDims(
		scope,
		floatCaster,
		op.Const(scope.SubScope("make_batch"), int32(0)),
	)

	//
	resized := op.ResizeBilinear(
		scope,
		dimsExpander,
		op.Const(scope.SubScope("size"), []int32{inputHeight, inputWidth}),
	)

	//
	output := op.Div(
		scope,
		op.Sub(scope, resized, op.Const(scope.SubScope("mean"), inputMean)),
		op.Const(scope.SubScope("scale"), inputStd),
	)

	//
	graph, err := scope.Finalize()
	if err != nil {
		panic(err)
	}

	//
	bytes, err := ioutil.ReadFile(fileName)
	if err != nil {
		panic(err)
	}

	// DecodeJpeg uses a scalar String-valued tensor as input.
	tensor, err := tf.NewTensor(string(bytes))
	if err != nil {
		panic(err)
	}

	//
	session, err := tf.NewSession(graph, nil)
	if err != nil {
		panic(err)
	}
	defer session.Close()
	result, err := session.Run(map[tf.Output]*tf.Tensor{fileReader: tensor}, []tf.Output{output}, nil)
	if err != nil {
		panic(err)
	}
	return result[0]
}

func scoreToLabels(scores []float32) string {
	return fmt.Sprintf("labio:%2.4f;normal:%2.4f", scores[0], scores[1])
}

func startImageLabeler(imgChan chan string, scoreChan chan map[string]float32) {

	// Load the serialized GraphDef from a file.
	modelfile, labelsfile := modelFiles()
	model, err := ioutil.ReadFile(modelfile)
	if err != nil {
		log.Fatal(err)
	}

	// Construct an in-memory graph from the serialized form.
	graph := tf.NewGraph()
	if err := graph.Import(model, ""); err != nil {
		log.Fatal(err)
	}

	// Create a session for inference over graph.
	session, err := tf.NewSession(graph, nil)
	if err != nil {
		log.Fatal(err)
	}
	defer session.Close()

	for imageFile := range imgChan {

		// Run inference on *imageFile.
		// For multiple images, session.Run() can be called in a loop (and
		// concurrently). Alternatively, images can be batched since the model
		// accepts batches of image data as input.
		func() {
			tensor, _, err := makeTensorFromImage(imageFile)
			//defer os.Remove(imageFile)
			if err != nil {
				log.Fatal(err)
			}

			argInput := graph.Operation("input").Output(0)
			argOutput := graph.Operation("output").Output(0)

			output, err := session.Run(
				map[tf.Output]*tf.Tensor{argInput: tensor},
				[]tf.Output{argOutput},
				nil)
			if err != nil {
				log.Fatal(err)
			}
			// output[0].Value() is a vector containing probabilities of
			// labels for each image in the "batch". The batch size was 1.
			// Find the most probably label index.
			probabilities := output[0].Value().([][]float32)[0]
			scoreChan <- labelScores(probabilities, labelsfile)
		}()
	}
}

func labelScores(probabilities []float32, labelsFile string) map[string]float32 {
	/*
		bestIdx := 0
		for i, p := range probabilities {
			if p > probabilities[bestIdx] {
				bestIdx = i
			}
		}
	*/
	// Found the best match. Read the string from labelsFile, which
	// contains one line per label.
	file, err := os.Open(labelsFile)
	if err != nil {
		log.Fatal(err)
	}
	defer file.Close()
	scanner := bufio.NewScanner(file)
	var labels []string
	for scanner.Scan() {
		labels = append(labels, scanner.Text())
	}
	if err := scanner.Err(); err != nil {
		log.Printf("ERROR: failed to read %s: %v", labelsFile, err)
	}
	//fmt.Printf("BEST MATCH: (%2.0f%% likely) %s\n", probabilities[bestIdx]*100.0, labels[bestIdx])
	m := make(map[string]float32)
	for i, v := range probabilities {
		m[labels[i]] = v
	}

	return m
}

// Convert the image in filename to a Tensor suitable as input to the Inception model.
func makeTensorFromImage(filename string) (*tf.Tensor, *op.Scope, error) {
	/*
		var elError error = nil
		defer func() {
			if r := recover(); r != nil {
				elError = fmt.Errorf("Recovered from : %s", r)
				fmt.Printf("Recovered from : %s", r)
			}
		}()
	*/

	bytes, err := ioutil.ReadFile(filename)
	if err != nil {
		return nil, nil, err
	}
	// DecodeJpeg uses a scalar String-valued tensor as input.
	tensor, err := tf.NewTensor(string(bytes))
	if err != nil {
		return nil, nil, err
	}

	// Construct a graph to normalize the image
	graph, input, output, scope, err := constructGraphToNormalizeImage(tensor)
	if err != nil {
		return nil, nil, err
	}
	// Execute that graph to normalize this one image
	session, err := tf.NewSession(graph, nil)
	if err != nil {
		return nil, nil, err
	}
	defer session.Close()
	normalized, err := session.Run(map[tf.Output]*tf.Tensor{input: tensor}, []tf.Output{output}, nil)
	if err != nil {
		return nil, nil, err
	}
	return normalized[0], scope, nil
}

// The inception model takes as input the image described by a Tensor in a very
// specific normalized format (a particular image size, shape of the input tensor,
// normalized pixel values etc.).
//
// This function constructs a graph of TensorFlow operations which takes as
// input a JPEG-encoded string and returns a tensor suitable as input to the
// inception model.
func constructGraphToNormalizeImage(imgInput *tf.Tensor) (graph *tf.Graph, input, output tf.Output, scope *op.Scope, err error) {
	// Some constants specific to the pre-trained model at:
	// https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip
	//
	// - The model was trained after with images scaled to 224x224 pixels.
	// - The colors, represented as R, G, B in 1-byte each were converted to
	//   float using (value - Mean)/Scale.
	const (
		H, W  = 280, 280
		Mean  = float32(117)
		Scale = float32(1)
	)
	// - input is a String-Tensor, where the string the JPEG-encoded image.
	// - The inception model takes a 4D tensor of shape
	//   [BatchSize, Height, Width, Colors=3], where each pixel is
	//   represented as a triplet of floats
	// - Apply normalization on each pixel and use ExpandDims to make
	//   this single image be a "batch" of size 1 for ResizeBilinear.
	s := op.NewScope()
	//input = op.Placeholder(s, tf.String)
	output = op.Div(s,
		op.Sub(s,
			op.ResizeBilinear(s,
				op.ExpandDims(
					s,
					//op.Cast(s, op.DecodeJpeg(s, input, op.DecodeJpegChannels(3)), tf.Float),
					op.Cast(s, op.DecodeJpeg(s, imgInput, op.DecodeJpegChannels(3)), tf.Float),
					op.Const(s.SubScope("make_batch"), int32(0)),
				),
				op.Const(s.SubScope("size"), []int32{H, W})),
			op.Const(s.SubScope("mean"), Mean)),
		op.Const(s.SubScope("scale"), Scale))
	graph, err = s.Finalize()
	return
	//return graph, input, output, s, err
}

func modelFiles() (string, string) {
	var (
		model  = "./retrained_graph.pb"
		labels = "./retrained_labels.txt"
	)
	return model, labels
}

func filesExist(files ...string) error {
	for _, f := range files {
		if _, err := os.Stat(f); err != nil {
			return fmt.Errorf("unable to stat %s: %v", f, err)
		}
	}
	return nil
}

func download(URL, filename string) error {
	resp, err := http.Get(URL)
	if err != nil {
		return err
	}
	defer resp.Body.Close()
	file, err := os.OpenFile(filename, os.O_RDWR|os.O_CREATE, 0644)
	if err != nil {
		return err
	}
	defer file.Close()
	_, err = io.Copy(file, resp.Body)
	return err
}

func unzip(dir, zipfile string) error {
	r, err := zip.OpenReader(zipfile)
	if err != nil {
		return err
	}
	defer r.Close()
	for _, f := range r.File {
		src, err := f.Open()
		if err != nil {
			return err
		}
		log.Println("Extracting", f.Name)
		dst, err := os.OpenFile(filepath.Join(dir, f.Name), os.O_WRONLY|os.O_CREATE, 0644)
		if err != nil {
			return err
		}
		if _, err := io.Copy(dst, src); err != nil {
			return err
		}
		dst.Close()
	}
	return nil
}

func tgRecognizer() {
	model := tg.LoadModel("./", []string{"retrained_graph"}, nil)
	fakeInput, _ := tf.NewTensor([1][28][1]float32{})
	results := model.Exec(
		[]tf.Output{
			model.Op("LeNetDropout/softmax_linear/Identity", 0),
		},
		map[tf.Output]*tf.Tensor{
			model.Op("input_", 0): fakeInput,
		},
	)
	predictions := results[0].Value().([][]float32)
	fmt.Println(predictions)
}
